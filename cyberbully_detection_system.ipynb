from transformers import pipeline
import re

# Initialize the AI-based toxicity detection model
model = pipeline('text-classification', model='unitary/toxic-bert')

# Expanded and more strict list of profanity and offensive phrases
PROFANITY_LIST = [
    'fuck', 'shit', 'bitch', 'asshole', 'bastard', 'dick', 'damn', 'slut',
    'whore', 'moron', 'stupid', 'idiot', 'suck', 'jerk', 'loser', 'dumb',
    'hell', 'crap', 'bloody', 'prick', 'freak', 'scumbag', 'twit', 'scum',
    'pig', 'fool', 'retar…go to hell', 'shame on you', 'screw you',
    'blow job', 'son of a bitch', 'douchebag', 'twat', 'hoe', 'crap', 'idiotic',
    'pathetic', 'trash', 'you suck', 'loser', 'die', 'kill yourself', 'piss off',
    'screw you', 'coward', 'worthless', 'imbecile', 'cretin', 'vulgar', 'annoying',
    'unwanted', 'disgusting', 'abnormal', 'deviant', 'dirty', 'nasty', 'foul', 'perverted',
    'corrupt', 'heinous', 'vile', 'evil', 'maniac', 'psycho', 'lunatic', 'weirdo', 'gross',
    'toxic', 'despicable'
]
# Function to check for profanity and offensive phrases
def contains_profanity(text):
    # Check if any word or phrase from the profanity list is in the input text
    pattern = re.compile(r'\b(?:' + '|'.join(re.escape(word) for word in PROFANITY_LIST) + r')\b', re.IGNORECASE)
    if pattern.search(text):
        return True
    return False

# Function to detect cyberbullying using the AI model and profanity check
def ai_detect_cyberbullying(text):
…    # Lower sensitivity threshold for maximum strictness
    if any(res['label'] in toxic_labels and res['score'] > 0.05 for res in result):
        return 'Cyberbullying detected! (AI)', True
    else:
        return 'No cyberbullying detected.', False
# Function to interact with the user and manage warnings
def detect_cyberbullying():
    print("Enter a message to check for cyberbullying (or type 'exit' to quit):")
    warning_count = 0  # Track the number of warnings
…        if warning_count >= 3:
            print("❌ You are suspended for 7 days due to repeated misbehavior.")
            break

# Run the system
detect_cyberbullying()
